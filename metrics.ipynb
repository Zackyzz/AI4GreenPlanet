{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T19:18:07.797207400Z",
     "start_time": "2023-11-18T19:18:03.953209500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "energy_data = pd.read_csv(\"Extra//energy.csv\")\n",
    "energy_data['timestamp'] = pd.to_datetime(energy_data['timestamp'])\n",
    "energy_data.set_index('timestamp', inplace=True)\n",
    "resampled_energy = energy_data.resample(\"5s\").mean()\n",
    "resampled_energy = resampled_energy.fillna(method='ffill')\n",
    "resampled_energy = resampled_energy.fillna(method='bfill')\n",
    "\n",
    "env_data = pd.read_csv(\"Extra//environment.csv\")\n",
    "env_data['timestamp'] = pd.to_datetime(env_data['timestamp'])\n",
    "env_data.set_index('timestamp', inplace=True)\n",
    "resampled_env = env_data.resample(\"5s\").mean()\n",
    "resampled_env = resampled_env.fillna(method='ffill')\n",
    "resampled_env = resampled_env.fillna(method='bfill')\n",
    "\n",
    "resampled_energy['reactive_power'] = resampled_energy[[\"Reactive Power A average [kVAr]\",\"Reactive Power B average [kVAr]\",\"Reactive Power C average [kVAr]\"]].mean(axis=1)\n",
    "resampled_energy['thdi'] = resampled_energy[[\"THDI A average [%]\",\"THDI B average [%]\",\"THDI C average [%]\"]].mean(axis=1)\n",
    "resampled_energy['thdu'] = resampled_energy[[\"THDU A average [%]\",\"THDU B average [%]\",\"THDU C average [%]\"]].mean(axis=1)\n",
    "resampled_energy['current'] = resampled_energy[[\"Current A average [A]\",\"Current B average [A]\",\"Current C average [A]\"]].mean(axis=1)\n",
    "resampled_energy['voltage'] = resampled_energy[[\"Voltage A average [V]\",\"Voltage B average [V]\",\"Voltage C average [V]\"]].mean(axis=1)\n",
    "resampled_energy['power_factor'] = resampled_energy[[\"Power Factor A average\",\"Power Factor B average\",\"Power Factor C average\"]].mean(axis=1)\n",
    "useful_data = resampled_energy.join(resampled_env)\n",
    "used_features = [\"reactive_power\",\"power_factor\",\"current\",\"voltage\",\"thdu\",\"thdi\",\"Xacc\",\"yaw\",\"pitch\"]\n",
    "useful_data = useful_data[used_features]\n",
    "useful_data = useful_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T19:18:07.998707Z",
     "start_time": "2023-11-18T19:18:07.798709400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load autoencoder anomalies\n",
    "autoencoder_anomalies = pd.read_csv(\"std_anomalies/autoencoder_anomalies_v2.csv\", index_col=\"Date\")\n",
    "autoencoder_anomalies.index = pd.to_datetime(autoencoder_anomalies.index, format='%Y-%m-%d %H:%M:%S')\n",
    "autoencoder_anomalies.rename(columns={\"modes\": \"modes_autoencoder\", \"Anomaly\": \"anomaly_autoencoder\"}, inplace=True)\n",
    "autoencoder_anomalies[\"anomaly_autoencoder\"] = autoencoder_anomalies[\"anomaly_autoencoder\"].replace({\"Yes\": True, \"No\": False})\n",
    "\n",
    "#load hmm anomalies\n",
    "hmm_anomalies = pd.read_csv(\"std_anomalies/hmm_anomalies_3std.csv\", index_col=\"Date\")\n",
    "hmm_anomalies.index = pd.to_datetime(hmm_anomalies.index, format='%Y-%m-%d %H:%M:%S')\n",
    "hmm_anomalies.rename(columns={\"modes\": \"modes_hmm\", \"Anomaly\": \"anomaly_hmm\"}, inplace=True)\n",
    "hmm_anomalies[\"anomaly_hmm\"] = hmm_anomalies[\"anomaly_hmm\"].replace({\"Yes\": True, \"No\": False})\n",
    "hmm_anomalies.head()\n",
    "\n",
    "# merge anomalies\n",
    "merged_df=pd.merge(useful_data,autoencoder_anomalies, how='inner', left_index=True, right_index=True)\n",
    "merged_df=pd.merge(merged_df,hmm_anomalies, how='inner', left_index=True, right_index=True)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T19:21:36.805230800Z",
     "start_time": "2023-11-18T19:21:36.676231100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for mode in merged_df['modes_autoencoder'].unique():\n",
    "    mode_data = merged_df[merged_df['modes_autoencoder'] == mode].copy()\n",
    "    mode_data_features = mode_data[used_features]\n",
    "\n",
    "    #scaling the data so the mean is 0 and the std is 1\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(mode_data_features)\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=used_features, index=mode_data.index)\n",
    "\n",
    "    anomalies = np.abs(scaled_df) > #3*std as in papers and the std is already 1 after scaling it\n",
    "    mode_data['std_anomaly_autoencoder'] = anomalies.any(axis=1)\n",
    "    merged_df.loc[mode_data.index, 'std_anomaly_autoencoder'] = mode_data['std_anomaly_autoencoder']\n",
    "\n",
    "for mode in merged_df['modes_hmm'].unique():\n",
    "    mode_data = merged_df[merged_df['modes_hmm'] == mode].copy()\n",
    "    mode_data_features = mode_data[used_features]\n",
    "\n",
    "    #scaling the data so the mean is 0 and the std is 1\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(mode_data_features)\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=used_features, index=mode_data.index)\n",
    "\n",
    "    anomalies = np.abs(scaled_df) > 3 # 3*std as in papers and the std is already 1 after scaling it\n",
    "    mode_data['std_anomaly_hmm'] = anomalies.any(axis=1)\n",
    "    merged_df.loc[mode_data.index, 'std_anomaly_hmm'] = mode_data['std_anomaly_hmm']\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T19:18:08.587207800Z",
     "start_time": "2023-11-18T19:18:08.575207500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score, f1_score, matthews_corrcoef\n",
    "import math\n",
    "\n",
    "def get_metrics(y_pred, y_true):\n",
    "    TP, FN, FP, TN = confusion_matrix(y_true, y_pred).ravel()\n",
    "    TPR = recall_score(y_true, y_pred)\n",
    "    TNR = TN / (TN + FP)\n",
    "    G_MEAN = math.sqrt(TPR * TNR)\n",
    "    PPV = precision_score(y_true, y_pred)\n",
    "    ACC = accuracy_score(y_true, y_pred)\n",
    "    F1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    MCC = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'RECALL': TPR,\n",
    "        'SPECIFICITY': TNR,\n",
    "        'PRECISION': PPV,\n",
    "        'ACCURACY': ACC,\n",
    "        'G_MEAN': G_MEAN,\n",
    "        'F1': F1,\n",
    "        'MCC': MCC\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T19:18:11.269206Z",
     "start_time": "2023-11-18T19:18:08.589206600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics_dict = {}\n",
    "\n",
    "for unique_mode in merged_df[\"modes_autoencoder\"].unique():\n",
    "    current_mode_df = merged_df[merged_df[\"modes_autoencoder\"] == unique_mode]\n",
    "    predicted_anomalies = current_mode_df['anomaly_autoencoder']\n",
    "\n",
    "    current_mode_df['std_anomaly_autoencoder'] = current_mode_df['std_anomaly_autoencoder'].astype(bool)\n",
    "    ground_truth = current_mode_df['std_anomaly_autoencoder']\n",
    "\n",
    "    mode_metrics = get_metrics(predicted_anomalies, ground_truth)\n",
    "    metrics_dict[unique_mode] = mode_metrics\n",
    "\n",
    "metrics_df = pd.DataFrame.from_dict(metrics_dict, orient='index')\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict_hmm = {}\n",
    "\n",
    "for unique_mode in merged_df[\"modes_hmm\"].unique():\n",
    "    current_mode_df = merged_df[merged_df[\"modes_hmm\"] == unique_mode]\n",
    "    predicted_anomalies = current_mode_df['anomaly_hmm']\n",
    "\n",
    "    current_mode_df['std_anomaly_hmm'] = current_mode_df['std_anomaly_hmm'].astype(bool)\n",
    "    ground_truth = current_mode_df['std_anomaly_hmm']\n",
    "\n",
    "    mode_metrics = get_metrics(predicted_anomalies, ground_truth)\n",
    "    metrics_dict_hmm[unique_mode] = mode_metrics\n",
    "\n",
    "metrics_df_hmm = pd.DataFrame.from_dict(metrics_dict_hmm, orient='index')\n",
    "metrics_df_hmm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
