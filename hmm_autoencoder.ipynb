{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "energy_data = pd.read_csv(\"Extra//energy.csv\")\n",
    "energy_data['timestamp'] = pd.to_datetime(energy_data['timestamp'])\n",
    "energy_data.set_index('timestamp', inplace=True)\n",
    "resampled_energy = energy_data.resample(\"5s\").mean()\n",
    "resampled_energy = resampled_energy.fillna(method='ffill')\n",
    "resampled_energy = resampled_energy.fillna(method='bfill')\n",
    "\n",
    "env_data = pd.read_csv(\"Extra//environment.csv\")\n",
    "env_data['timestamp'] = pd.to_datetime(env_data['timestamp'])\n",
    "env_data.set_index('timestamp', inplace=True)\n",
    "resampled_env = env_data.resample(\"5s\").mean()\n",
    "resampled_env = resampled_env.fillna(method='ffill')\n",
    "resampled_env = resampled_env.fillna(method='bfill')\n",
    "\n",
    "resampled_energy['reactive_power'] = resampled_energy[[\"Reactive Power A average [kVAr]\",\"Reactive Power B average [kVAr]\",\"Reactive Power C average [kVAr]\"]].mean(axis=1)\n",
    "resampled_energy['thdi'] = resampled_energy[[\"THDI A average [%]\",\"THDI B average [%]\",\"THDI C average [%]\"]].mean(axis=1)\n",
    "resampled_energy['thdu'] = resampled_energy[[\"THDU A average [%]\",\"THDU B average [%]\",\"THDU C average [%]\"]].mean(axis=1)\n",
    "resampled_energy['current'] = resampled_energy[[\"Current A average [A]\",\"Current B average [A]\",\"Current C average [A]\"]].mean(axis=1)\n",
    "resampled_energy['voltage'] = resampled_energy[[\"Voltage A average [V]\",\"Voltage B average [V]\",\"Voltage C average [V]\"]].mean(axis=1)\n",
    "resampled_energy['power_factor'] = resampled_energy[[\"Power Factor A average\",\"Power Factor B average\",\"Power Factor C average\"]].mean(axis=1)\n",
    "useful_data = resampled_energy.join(resampled_env)\n",
    "useful_data = useful_data[[\"reactive_power\",\"power_factor\",\"current\",\"voltage\",\"thdu\",\"thdi\",\"Xacc\",\"yaw\",\"pitch\"]]\n",
    "useful_data = useful_data.dropna()\n",
    "display(useful_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(useful_data[useful_data.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "np.random.seed(33)\n",
    "\n",
    "n_clusters = 5\n",
    "model = hmm.GaussianHMM(n_components = n_clusters, covariance_type='diag')\n",
    "model.fit(scaled_data)\n",
    "hidden_states = model.predict(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "normalized_plot_data = pd.DataFrame(scaler.fit_transform(useful_data.values), columns=useful_data.columns, index=useful_data.index)\n",
    "\n",
    "normalized_plot_data = normalized_plot_data.assign(states = hidden_states)\n",
    "normalized_plot_data.insert(loc=0, column='Date', value=pd.to_datetime(normalized_plot_data.index))\n",
    "normalized_plot_data['modes'] = normalized_plot_data['states'].map({0:'Offline', 1: 'InMotion', 2: 'Mode2', 3: 'Online', 4:'Mode1'})\n",
    "color_map = {\"Offline\": \"black\", \"InMotion\": \"Green\", \"Online\": \"white\", \"Mode1\": \"yellow\", \"Mode2\" : \"magenta\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "plot_data = normalized_plot_data.loc['2022-11-16 13:50:00':'2022-11-16 16:10:00']\n",
    "\n",
    "fig = px.line(plot_data, x='Date', y='current')\n",
    "fig.update_traces(line=dict(color='black'))\n",
    "fig.update_layout(xaxis_title=\"Time\", yaxis_title=\"Current average [A]\", xaxis=dict(showgrid=False), yaxis=dict(showgrid=False))\n",
    "\n",
    "#start background\n",
    "start_mode = str(plot_data.iloc[0][\"modes\"])\n",
    "start_date = str(plot_data.iloc[0][\"Date\"])\n",
    "\n",
    "for index, row in plot_data.iterrows():\n",
    "    current_mode = row[\"modes\"]\n",
    "    if current_mode != start_mode:\n",
    "        fig.add_vrect(x0=start_date, x1=str(row[\"Date\"]), fillcolor=color_map[start_mode], opacity=0.5)\n",
    "        start_mode = row[\"modes\"]\n",
    "        start_date = str(row[\"Date\"])\n",
    "\n",
    "fig.add_vrect(x0=start_date, x1=str(plot_data.iloc[-1][\"Date\"]), fillcolor=color_map[start_mode], opacity=0.5)\n",
    "for state, color in color_map.items():\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None],\n",
    "                             mode='markers',\n",
    "                             marker=dict(size=10, color=color),\n",
    "                             name=state))\n",
    "\n",
    "#end background\n",
    "fig.update_layout(height=600,width=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data for anomaly detection\n",
    "anomaly_data = resampled_energy.join(resampled_env)\n",
    "anomaly_data = anomaly_data[[\"reactive_power\",\"power_factor\",\"current\",\"voltage\",\"thdu\",\"thdi\",\"Xacc\",\"yaw\",\"pitch\"]] #features to detect anomalies on\n",
    "hidden_states = normalized_plot_data[\"states\"]\n",
    "hidden_states_aligned = hidden_states.reindex(anomaly_data.index)\n",
    "anomaly_data = anomaly_data.assign(states=hidden_states_aligned)\n",
    "anomaly_data = anomaly_data.dropna()\n",
    "anomaly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_data = []\n",
    "clusters_indices = []\n",
    "std_data = []\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    cluster_data = anomaly_data[anomaly_data['states'] == i]\n",
    "    clusters_data.append(cluster_data)\n",
    "    cluster_indices = np.where(anomaly_data['states'].values == i)[0]\n",
    "    clusters_indices.append(cluster_indices)\n",
    "    temp_data = (cluster_data - cluster_data.mean()) / cluster_data.std()\n",
    "    std_data.append(temp_data.stack().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "def create_autoencoder(timesteps, n_features):\n",
    "    autoencoder = Sequential([\n",
    "        Bidirectional(LSTM(64, activation='tanh', return_sequences=True), input_shape=(timesteps, n_features)),\n",
    "        Bidirectional(LSTM(32, activation='tanh', return_sequences=False)),\n",
    "        RepeatVector(timesteps),\n",
    "        Bidirectional(LSTM(32, activation='tanh', return_sequences=True)),\n",
    "        Bidirectional(LSTM(64, activation='tanh', return_sequences=True)),\n",
    "        TimeDistributed(Dense(n_features))\n",
    "    ])\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 10\n",
    "all_anomalies = []\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    cluster_df = clusters_data[i].drop(columns=['states'])\n",
    "    cluster_df = cluster_df.iloc[:-(timesteps + (cluster_df.shape[0] % timesteps))]\n",
    "    scaled_cluster = standard_scaler.fit_transform(cluster_df.values)\n",
    "    \n",
    "    n_samples = scaled_cluster.shape[0] // timesteps\n",
    "    reshaped_scaled_cluster = scaled_cluster.reshape(scaled_cluster.shape[0]//timesteps, timesteps, scaled_cluster.shape[1])\n",
    "    n_features = reshaped_scaled_cluster.shape[2]\n",
    "\n",
    "    autoencoder = create_autoencoder(timesteps, n_features)\n",
    "    autoencoder.fit(reshaped_scaled_cluster, reshaped_scaled_cluster, epochs=20, batch_size=32, verbose=1)\n",
    "    \n",
    "    predictions = autoencoder.predict(reshaped_scaled_cluster)\n",
    "    predictions = predictions.reshape(predictions.shape[0] * predictions.shape[1], predictions.shape[2])\n",
    "\n",
    "    mse = np.square(np.subtract(scaled_cluster, predictions))\n",
    "    threshold = np.percentile(mse, 99.73)\n",
    "\n",
    "    anomalies = np.where(mse > threshold)\n",
    "    original_datetime_indices = [clusters_indices[i][x] for x in anomalies[0]]\n",
    "    original_indices = [original_datetime_indices, anomalies[1]]\n",
    "\n",
    "    all_anomalies.append(original_indices)\n",
    "\n",
    "display(all_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = [index for cluster in all_anomalies for index in cluster[0]]\n",
    "unique_indices = __builtins__.set(all_indices)\n",
    "unique_indices_list = sorted(list(unique_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_plot_data['Anomaly'] = 'No'\n",
    "normalized_plot_data.iloc[unique_indices_list, normalized_plot_data.columns.get_loc('Anomaly')] = 'Yes'\n",
    "normalized_plot_data.reset_index(inplace=True)\n",
    "normalized_plot_data.set_index('timestamp', inplace=True)\n",
    "normalized_plot_data[['Date', 'modes', 'Anomaly']].to_csv('autoencoder_anomalies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "plot_df = pd.DataFrame(scaler.fit_transform(anomaly_data.values), columns=anomaly_data.columns, index=anomaly_data.index)\n",
    "\n",
    "for cluster in all_anomalies:\n",
    "    for anomaly_group in list(zip(cluster[0], cluster[1])):\n",
    "        anomaly = anomaly_group[0]\n",
    "        if anomaly < 100:\n",
    "            continue\n",
    "        bg_df = normalized_plot_data.loc[str(normalized_plot_data.iloc[anomaly-100][\"Date\"]):str(normalized_plot_data.iloc[anomaly+100][\"Date\"])]\n",
    "        new_df = plot_df.loc[str(normalized_plot_data.iloc[anomaly-100][\"Date\"]):str(normalized_plot_data.iloc[anomaly+100][\"Date\"])]\n",
    "        new_df.insert(loc=0,column='Date', value=pd.to_datetime(new_df.index))\n",
    "\n",
    "        line_fig = px.line(new_df, x = 'Date', y = anomaly_data.columns[anomaly_group[1]])\n",
    "        line_fig.update_traces(line=dict(color = 'black'))\n",
    "        fig = go.Figure(data=line_fig.data).update_layout(xaxis_title=\"Time\", yaxis_title=anomaly_data.columns[anomaly_group[1]])\n",
    "\n",
    "        bg_df['modes'] = bg_df['states'].map({0:'Offline', 1: 'InMotion', 2: 'Mode2', 3: 'Online', 4:'Mode1'})\n",
    "        color_map = {\"Offline\": \"black\", \"InMotion\": \"Green\", \"Online\": \"white\", \"Mode1\": \"yellow\", \"Mode2\" : \"magenta\"}\n",
    "        \n",
    "        #start background\n",
    "        start_mode = str(bg_df.iloc[0][\"modes\"])\n",
    "        start_date = str(bg_df.iloc[0][\"Date\"])\n",
    "\n",
    "        for index, row in bg_df.iterrows():\n",
    "            current_mode = row[\"modes\"]\n",
    "            if current_mode != start_mode:\n",
    "                fig.add_vrect(x0=start_date, x1=str(row[\"Date\"]), fillcolor=color_map[start_mode], opacity=0.5)\n",
    "                start_mode = row[\"modes\"]\n",
    "                start_date = str(row[\"Date\"])\n",
    "\n",
    "        fig.add_vrect(x0=start_date, x1=str(bg_df.iloc[-1][\"Date\"]), fillcolor=color_map[start_mode], opacity=0.5)\n",
    "\n",
    "        #fig.add_vrect(x0=str(useful_data.iloc[anomaly-5].name),x1=str(useful_data.iloc[anomaly-3].name),fillcolor=\"black\", opacity=1)\n",
    "        #fig.add_vrect(x0=str(useful_data.iloc[anomaly+4].name),x1=str(useful_data.iloc[anomaly+6].name),fillcolor=\"black\", opacity=1)\n",
    "        fig.add_vrect(x0=str(anomaly_data.iloc[anomaly-1].name),x1=str(anomaly_data.iloc[anomaly+1].name),fillcolor=\"red\", opacity=0.5)\n",
    "        #end background\n",
    "\n",
    "        fig.update_layout(xaxis=dict(showgrid=False), yaxis=dict(showgrid=False))\n",
    "        fig.add_vrect(x0=start_date, x1=str(new_df.iloc[-1][\"Date\"]), fillcolor=color_map[start_mode], opacity=0.5)\n",
    "        for state, color in color_map.items():\n",
    "            fig.add_trace(go.Scatter(x=[None], y=[None],\n",
    "                                    mode='markers',\n",
    "                                    marker=dict(size=10, color=color),\n",
    "                                    name=state))\n",
    "        fig.add_trace(go.Scatter(x=[None], y=[None], mode='markers', marker=dict(size=10, color='Red', symbol='square'), name = 'Anomaly'))\n",
    "\n",
    "        #end background\n",
    "        fig.update_layout(\n",
    "            height=600,\n",
    "            width=1000\n",
    "        )\n",
    "        fig.update_layout(height=600,width=1000)\n",
    "        fig.show()\n",
    "        #fig.write_image(f\"pics/ae/anomaly_{anomaly_data.columns[i[1]]}_{(anomaly_data.iloc[anomaly].name).strftime('%Y_%m_%d-%I_%M_%S')}.jpg\", width=1920, height=0.75*1080)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2572ea1b1ef9c8d2ad1a91dec6289fcd3897516dc536ea19b4e38370c1a20702"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
