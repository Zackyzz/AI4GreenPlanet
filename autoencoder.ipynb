{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "energy_data = pd.read_csv(\"Extra//energy.csv\")\n",
    "env_data = pd.read_csv(\"Extra//environment.csv\")\n",
    "\n",
    "energy_data.timestamp = pd.to_datetime(energy_data.timestamp, format='%Y-%m-%d %H:%M:%S')\n",
    "energy_data.index = energy_data.timestamp\n",
    "resampled_df = energy_data.resample(\"2s\").mean()\n",
    "\n",
    "env_data.timestamp = pd.to_datetime(env_data.timestamp, format='%Y-%m-%d %H:%M:%S')\n",
    "env_data.index = env_data.timestamp\n",
    "resampled_env = env_data.resample(\"2s\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df['reactive_power'] = resampled_df[[\"Reactive Power A average [kVAr]\",\"Reactive Power B average [kVAr]\",\"Reactive Power C average [kVAr]\"]].mean(axis=1)\n",
    "resampled_df['thdi'] = resampled_df[[\"THDI A average [%]\",\"THDI B average [%]\",\"THDI C average [%]\"]].mean(axis=1)\n",
    "resampled_df['thdu'] = resampled_df[[\"THDU A average [%]\",\"THDU B average [%]\",\"THDU C average [%]\"]].mean(axis=1)\n",
    "resampled_df['current'] = resampled_df[[\"Current A average [A]\",\"Current B average [A]\",\"Current C average [A]\"]].mean(axis=1)\n",
    "resampled_df['power_factor'] = resampled_df[[\"Power Factor A average\",\"Power Factor B average\",\"Power Factor C average\"]].mean(axis=1)\n",
    "resampled_df = resampled_df.join(resampled_env)\n",
    "useful_data = resampled_df[[\"reactive_power\", \"thdi\", \"current\",\"power_factor\",\"Xacc\", \"pitch\"]]\n",
    "useful_data = useful_data.dropna()\n",
    "useful_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#scaled_df = pd.DataFrame(scaler.fit_transform(useful_data.values), columns=useful_data.columns, index=useful_data.index)\n",
    "useful_df = scaler.fit_transform(useful_data)\n",
    "scaled_df = useful_df.reshape(useful_df.shape[0], 1, useful_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, RepeatVector\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(scaled_df.shape[1], scaled_df.shape[2]))\n",
    "encoded = LSTM(80, activation='relu', return_sequences=True)(inputs)\n",
    "encoded = LSTM(80, activation='relu')(encoded)\n",
    "decoded = RepeatVector(1)(encoded)\n",
    "decoded = LSTM(80, activation='relu', return_sequences=True)(decoded)\n",
    "decoded = LSTM(80, activation='relu', return_sequences=True)(decoded)\n",
    "decoded = LSTM(scaled_df.shape[2], activation='relu')(decoded)\n",
    "autoencoder = Model(inputs, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.fit(scaled_df, scaled_df, epochs=15, batch_size=80)\n",
    "predictions = autoencoder.predict(scaled_df)\n",
    "mse = np.square(np.subtract(useful_df, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = np.where(mse > 1000)[0]\n",
    "anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "plot_df = pd.DataFrame(scaler.fit_transform(useful_data.values), columns=useful_data.columns, index=useful_data.index)\n",
    "\n",
    "for i in anomalies[:5]:\n",
    "    anomaly = i\n",
    "    start = str(useful_data.iloc[anomaly-100].name)\n",
    "    final = str(useful_data.iloc[anomaly+100].name)\n",
    "\n",
    "    new_df = plot_df.loc[start:final]\n",
    "    new_df.insert(loc=0,column='Date', value=pd.to_datetime(new_df.index))\n",
    "\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    fig = px.line(new_df, x = 'Date', y = new_df.columns)\n",
    "    fig = go.Figure(data=fig.data).update_layout(xaxis_title=\"Time\", yaxis_title=\"Data\")\n",
    "\n",
    "    fig.add_vrect(x0=str(useful_data.iloc[anomaly-5].name),x1=str(useful_data.iloc[anomaly-4].name),fillcolor=\"black\", opacity=1)\n",
    "    fig.add_vrect(x0=str(useful_data.iloc[anomaly+5].name),x1=str(useful_data.iloc[anomaly+6].name),fillcolor=\"black\", opacity=1)\n",
    "    fig.add_vrect(x0=str(useful_data.iloc[anomaly].name),x1=str(useful_data.iloc[anomaly+1].name),fillcolor=\"black\", opacity=0.1)\n",
    "\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2572ea1b1ef9c8d2ad1a91dec6289fcd3897516dc536ea19b4e38370c1a20702"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
